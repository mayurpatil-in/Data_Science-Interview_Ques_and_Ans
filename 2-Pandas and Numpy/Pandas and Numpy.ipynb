{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' \\nMention the different types of Data Structures in Pandas?\\n\\nSeries:\\n\\nIt is a one-dimensional array-like structure with homogeneous data which means data of different data types cannot be a part of the same series. It can hold any data type such as integers, floats, and strings and its values are mutable i.e. it can be changed but the size of the series is immutable i.e. it cannot be changed. By using a ‘series’ method, we can easily convert the list, tuple, and dictionary into a series. A Series cannot contain multiple columns.\\n\\nDataFrame : \\nIt is a two-dimensional array-like structure with heterogeneous data. It can contain data of different data types and the data is aligned in a tabular manner i.e. in rows and columns and the indexes with respect to these are called row index and column index respectively. Both size and values of DataFrame are mutable. The columns can be heterogeneous types like int and bool. It can also be defined as a dictionary of Series.\\n\\n\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "Mention the different types of Data Structures in Pandas?\n",
    "\n",
    "Series:\n",
    "\n",
    "It is a one-dimensional array-like structure with homogeneous data which means data of different data types cannot be a part of the same series. It can hold any data type such as integers, floats, and strings and its values are mutable i.e. it can be changed but the size of the series is immutable i.e. it cannot be changed. By using a ‘series’ method, we can easily convert the list, tuple, and dictionary into a series. A Series cannot contain multiple columns.\n",
    "\n",
    "DataFrame : \n",
    "It is a two-dimensional array-like structure with heterogeneous data. It can contain data of different data types and the data is aligned in a tabular manner i.e. in rows and columns and the indexes with respect to these are called row index and column index respectively. Both size and values of DataFrame are mutable. The columns can be heterogeneous types like int and bool. It can also be defined as a dictionary of Series.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    " What are the significant features of the pandas Library?\n",
    "\n",
    "\n",
    "Fast and efficient DataFrame object with default and customized indexing.\n",
    "High-performance merging and joining of data.\n",
    "Data alignment and integrated handling of missing data.\n",
    "Label-based slicing, indexing, and subsetting of large data sets.\n",
    "Reshaping and pivoting of data sets.\n",
    "Tools for loading data into in-memory data objects from different file formats.\n",
    "Columns from a data structure can be deleted or inserted.\n",
    "Group by data for aggregation and transformations.\n",
    "Time Series functionality.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: object)\n",
      "0    s\n",
      "1    c\n",
      "2    a\n",
      "3    l\n",
      "4    a\n",
      "5    r\n",
      "dtype: object\n",
      "0    s\n",
      "1    c\n",
      "2    a\n",
      "3    l\n",
      "4    a\n",
      "5    r\n",
      "dtype: object\n",
      "A    101\n",
      "B    202\n",
      "C    303\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Different ways to create series in pandas?\n",
    "\n",
    "creating empty sereis \n",
    "creating series from an array \n",
    "creating series from an array with index \n",
    "creating series from a dictionary\n",
    "creating series from a list \n",
    "creating series from s scaler value \n",
    "\n",
    "\"\"\" \n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ser = pd.Series()\n",
    "\n",
    "print(ser)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = np.array(['s', 'c', 'a', 'l', 'a','r'])\n",
    "\n",
    "ser = pd.Series(data)\n",
    "print(ser)\n",
    "\n",
    "\n",
    "\n",
    "data = np.array(['s', 'c', 'a', 'l', 'a','r'])\n",
    "\n",
    "ser = pd.Series(data, index=[10, 11, 12, 13, 14,15])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "list = ['s', 'c', 'a', 'l', 'a','r']\n",
    "\n",
    "ser = pd.Series(list)\n",
    "print(ser)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dict = {'A': 101,\n",
    "\t\t'B': 202,\n",
    "\t\t'C': 303}\n",
    "\n",
    "ser = pd.Series(dict)\n",
    "\n",
    "print(ser)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# giving a scalar value with index\n",
    "ser = pd.Series(10, index=[0, 1, 2, 3, 4, 5])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    s\n",
       "11    c\n",
       "12    a\n",
       "13    l\n",
       "14    a\n",
       "15    r\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "data = np.array(['s', 'c', 'a', 'l', 'a','r'])\n",
    "\n",
    "ser = pd.Series(data, index=[10, 11, 12, 13, 14,15])\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    101\n",
      "B    202\n",
      "C    303\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dict = {'A': 101,\n",
    "\t\t'B': 202,\n",
    "\t\t'C': 303 }\n",
    "\n",
    "ser = pd.Series(dict)\n",
    "\n",
    "print(ser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    10\n",
       "1    10\n",
       "2    10\n",
       "3    10\n",
       "4    10\n",
       "5    10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser = pd.Series(10, index=[0, 1, 2, 3, 4, 5])\n",
    "ser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "   Amounts\n",
      "0      110\n",
      "1      202\n",
      "2      303\n",
      "3      404\n",
      "4      550\n",
      "5      650\n",
      "   Name  Age\n",
      "0  mark   20\n",
      "1  zack   16\n",
      "2   ron   24\n",
      "     Name  Age\n",
      "0     Max   10\n",
      "1    Lara   31\n",
      "2    Koke   91\n",
      "3  muller   48\n",
      "   aa  bs  cd\n",
      "0   1   2   3\n",
      "1  10  20  30\n",
      "    0\n",
      "0  10\n",
      "1  20\n",
      "2  30\n",
      "3  40\n",
      "   one  two\n",
      "a   10   10\n",
      "b   20   20\n",
      "c   30   30\n",
      "d   40   40\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "crating diffent types of dataframe ?\n",
    "\n",
    "create an empty dataframe \n",
    "creating dataframe from a dict of ndarray/lists \n",
    "creating dataframe using list \n",
    "creating dataframe using list using a dictionary \n",
    "creating dataframe using a series\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = [110,202,303,404,550,650]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Amounts'])\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = [['mark', 20], ['zack', 16], ['ron', 24]]\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Name', 'Age'])\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Name': ['Max', 'Lara', 'Koke', 'muller'],\n",
    "\t\t'Age': [10, 31, 91, 48]}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "data = [{'aa': 1, 'bs': 2, 'cd': 3},\n",
    "\t\t{'aa': 10, 'bs': 20, 'cd': 30}]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "d = pd.Series([10, 20, 30, 40])\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "d = {'one': pd.Series([10, 20, 30, 40],\n",
    "\t\t\t\t\tindex=['a', 'b', 'c', 'd']),\n",
    "\t'two': pd.Series([10, 20, 30, 40],\n",
    "\t\t\t\t\tindex=['a', 'b', 'c', 'd'])}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(d)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   aa  bs  cd\n",
      "0   1   2   3\n",
      "1  10  20  30\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = [{'aa': 1, 'bs': 2, 'cd': 3},\n",
    "\t\t{'aa': 10, 'bs': 20, 'cd': 30}]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    s\n",
      "1    c\n",
      "2    a\n",
      "3    l\n",
      "4    a\n",
      "5    r\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    s\n",
       "1    c\n",
       "2    a\n",
       "3    l\n",
       "4    a\n",
       "5    r\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" \n",
    "How can we create a copy of the series in Pandas?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "list = ['s', 'c', 'a', 'l', 'a','r']\n",
    "\n",
    "ser = pd.Series(list)\n",
    "print(ser)\n",
    "ser.copy(deep = True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "categoriacal data in python :\n",
    "\n",
    "Categorical data is a discrete set of values for a particular outcome and has a fixed range. Also, the data in the category need not be numerical, it can be textual in nature. Examples are gender, social class, blood type, country affiliation, observation time, etc. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Values\n",
      "Group Subgroup        \n",
      "A     a              1\n",
      "      b              2\n",
      "B     a              3\n",
      "      b              4\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "\n",
    "MultiIndexing in Python, particularly within libraries like Pandas, is a method of handling and organizing data with multiple levels of indexing. It allows you to work with data that has more than one key to index,\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "index = pd.MultiIndex.from_product([['A', 'B'], ['a', 'b']], names=['Group', 'Subgroup'])\n",
    "data = {'Values': [1, 2, 3, 4]}\n",
    "df = pd.DataFrame(data, index=index)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4 7]\n",
      " [2 5 8]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  \n",
    "covert dataframe to numpy array :  \n",
    "\n",
    "Pandas DataFrame to a NumPy array using the values attribute of the DataFrame. The values attribute returns a NumPy array representation of the DataFrame's data\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "numpy_array = df.values\n",
    "print(numpy_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 4 7]\n",
      " [2 5 8]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "numpy_array = df.values\n",
    "print(numpy_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "how to convert dataframe to excel file in pandas?\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "file_path = 'data.xlsx'\n",
    "\n",
    "\n",
    "df.to_excel(file_path, index=False)\n",
    "df1=df.to_csv(file_path)  # Set index=False to not write row numbers as index\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 days 05:05:05.005005005\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "timedelta in python ?\n",
    "\n",
    "A Timedelta can represent differences in time at various resolutions (days, hours, minutes, seconds, milliseconds, microseconds, and nanoseconds). You can create a Timedelta object by subtracting two dates or times, or by using the pd.Timedelta() constructor.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd \n",
    "td  = pd.Timedelta(days = 5, hours = 5, minutes = 5, seconds = 5, milliseconds = 5, microseconds = 5, nanoseconds = 5)\n",
    "print(td)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 days 00:00:00\n",
      "2022-01-06 00:00:00\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "start_date = pd.Timestamp('2022-01-01')\n",
    "end_date = pd.Timestamp('2022-01-10')\n",
    "\n",
    "\n",
    "duration = end_date - start_date\n",
    "print(duration)\n",
    "\n",
    "\n",
    "new_date = start_date + pd.Timedelta(days=5)\n",
    "print(new_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nIs iterating over a Pandas Dataframe a good practice? \\nIf not what are the important conditions to keep in mind before iterating?\\n\\nIdeally, iterating over pandas DataFrames is definitely not the best practice and one should only consider doing so when it is absolutely necessary and no other function is applicable. The iteration process through DataFrames is very inefficient. Pandas provide a lot of functions using which an operation can be executed without iterating through the dataframe. There are certain conditions that need to be checked before\\n\\nBefore attempting to iterate through pandas objects, we must first ensure that none of the below-stated conditions aligns with our use case:\\n\\nApplying a function to rows: \\n\\nA common use case of iteration is when it comes to applying a function to every row, which is designed to work only one row at a time and cannot be applied on the full DataFrame or Series. In such cases, it’s always recommended to use apply() method instead of iterating through the pandas object.\\n\\nIterative manipulations: \\n\\nIn case we need to perform iterative manipulations and at the same time performance is a major area of concern, then we have alternatives like numba and cython.\\n\\nPrinting a DataFrame: \\n\\nIf we want to print out a DataFrame then instead of iterating through the whole DataFrame we can simply use DataFrame.to_string() method in order to render the DataFrame to a console-friendly tabular output.\\n\\n\\nVectorisation over iteration:\\n\\n It is always preferred to choose vectorization over iteration as pandas come with a rich set of built-in methods whose performance is highly optimized and super efficient.\\n\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Is iterating over a Pandas Dataframe a good practice? \n",
    "If not what are the important conditions to keep in mind before iterating?\n",
    "\n",
    "Ideally, iterating over pandas DataFrames is definitely not the best practice and one should only consider doing so when it is absolutely necessary and no other function is applicable. The iteration process through DataFrames is very inefficient. Pandas provide a lot of functions using which an operation can be executed without iterating through the dataframe. There are certain conditions that need to be checked before\n",
    "\n",
    "Before attempting to iterate through pandas objects, we must first ensure that none of the below-stated conditions aligns with our use case:\n",
    "\n",
    "Applying a function to rows: \n",
    "\n",
    "A common use case of iteration is when it comes to applying a function to every row, which is designed to work only one row at a time and cannot be applied on the full DataFrame or Series. In such cases, it’s always recommended to use apply() method instead of iterating through the pandas object.\n",
    "\n",
    "Iterative manipulations: \n",
    "\n",
    "In case we need to perform iterative manipulations and at the same time performance is a major area of concern, then we have alternatives like numba and cython.\n",
    "\n",
    "Printing a DataFrame: \n",
    "\n",
    "If we want to print out a DataFrame then instead of iterating through the whole DataFrame we can simply use DataFrame.to_string() method in order to render the DataFrame to a console-friendly tabular output.\n",
    "\n",
    "\n",
    "Vectorisation over iteration:\n",
    "\n",
    " It is always preferred to choose vectorization over iteration as pandas come with a rich set of built-in methods whose performance is highly optimized and super efficient.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using iterrows():\n",
      "Row 0: Sum = 5\n",
      "Row 1: Sum = 7\n",
      "Row 2: Sum = 9\n",
      "\n",
      "Using apply() with axis=1:\n",
      "   A  B  Sum\n",
      "0  1  4    5\n",
      "1  2  5    7\n",
      "2  3  6    9\n",
      "\n",
      "Using a traditional loop with iloc[]:\n",
      "Row 0: Sum = 5\n",
      "Row 1: Sum = 7\n",
      "Row 2: Sum = 9\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "how to iterate over rows in pandas dataframe\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "\n",
    "# Method 1: Using iterrows()\n",
    "print(\"Using iterrows():\")\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Row {index}: Sum = {row['A'] + row['B']}\")\n",
    "\n",
    "\n",
    "# Method 2: Using apply() with axis=1\n",
    "print(\"\\nUsing apply() with axis=1:\")\n",
    "def sum_row(row):\n",
    "    return row['A'] + row['B']\n",
    "df['Sum'] = df.apply(sum_row, axis=1)\n",
    "print(df)\n",
    "\n",
    "\n",
    "\n",
    "# Method 3: Using a traditional loop with iloc[]\n",
    "print(\"\\nUsing a traditional loop with iloc[]:\")\n",
    "for i in range(len(df)):\n",
    "    print(f\"Row {i}: Sum = {df.iloc[i]['A'] + df.iloc[i]['B']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 2, 3, None, 5],\n",
    "        'C': [1, 2, 3, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "missing_values = df.isna()  # or df.isnull()\n",
    "print(\"Missing values before handling:\\n\", missing_values)\n",
    "\n",
    "# Fill missing values with the mean of the respective column\n",
    "df_filled = df.fillna(df.mean())\n",
    "print(\"\\nDataFrame after filling missing values with the mean:\\n\", df_filled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>3.333333</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A         B  C\n",
       "0  1.0  3.333333  1\n",
       "1  2.0  2.000000  2\n",
       "2  3.0  3.000000  3\n",
       "3  4.0  3.333333  4\n",
       "4  5.0  5.000000  5"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 2, 3, None, 5],\n",
    "        'C': [1, 2, 3, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "df.isna()\n",
    "df.isnull()\n",
    "df_filled = df.fillna(df.mean())\n",
    "df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values before handling:\n",
      "        A      B      C\n",
      "0  False   True  False\n",
      "1  False  False  False\n",
      "2   True  False  False\n",
      "3  False   True  False\n",
      "4  False  False  False\n",
      "\n",
      "DataFrame after dropping rows with missing values:\n",
      "      A    B  C\n",
      "1  2.0  2.0  2\n",
      "4  5.0  5.0  5\n",
      "\n",
      "DataFrame after filling missing values with a specific value:\n",
      "      A    B  C\n",
      "0  1.0  0.0  1\n",
      "1  2.0  2.0  2\n",
      "2  0.0  3.0  3\n",
      "3  4.0  0.0  4\n",
      "4  5.0  5.0  5\n",
      "\n",
      "DataFrame after filling missing values with the mean:\n",
      "      A         B  C\n",
      "0  1.0  3.333333  1\n",
      "1  2.0  2.000000  2\n",
      "2  3.0  3.000000  3\n",
      "3  4.0  3.333333  4\n",
      "4  5.0  5.000000  5\n",
      "\n",
      "DataFrame after interpolating missing values:\n",
      "      A    B  C\n",
      "0  1.0  NaN  1\n",
      "1  2.0  2.0  2\n",
      "2  3.0  3.0  3\n",
      "3  4.0  4.0  4\n",
      "4  5.0  5.0  5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'  \\nInterpolating Along Columns or Rows:\\nThe interpolate() function in pandas allows you to interpolate along either the rows or the columns of a DataFrame, depending on the axis parameter. This flexibility allows you to handle different data structures effectively.\\n\\n\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {'A': [1, 2, None, 4, 5],\n",
    "        'B': [None, 2, 3, None, 5],\n",
    "        'C': [1, 2, 3, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = df.isna()  # or df.isnull()\n",
    "print(\"Missing values before handling:\\n\", missing_values)\n",
    "\n",
    "\n",
    "\n",
    "df_dropped = df.dropna()\n",
    "print(\"\\nDataFrame after dropping rows with missing values:\\n\", df_dropped)\n",
    "\n",
    "\n",
    "\n",
    "df_filled_value = df.fillna(0)\n",
    "print(\"\\nDataFrame after filling missing values with a specific value:\\n\", df_filled_value)\n",
    "\n",
    "\n",
    "df_filled_mean = df.fillna(df.mean())\n",
    "print(\"\\nDataFrame after filling missing values with the mean:\\n\", df_filled_mean)\n",
    "\n",
    "# Option 4: Interpolate missing values\n",
    "df_interpolated = df.interpolate()\n",
    "print(\"\\nDataFrame after interpolating missing values:\\n\", df_interpolated)\n",
    "\n",
    "\n",
    "\"\"\"  \n",
    "Interpolating Along Columns or Rows:\n",
    "The interpolate() function in pandas allows you to interpolate along either the rows or the columns of a DataFrame, depending on the axis parameter. This flexibility allows you to handle different data structures effectively.\n",
    "\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B\n",
      "3  4   9\n",
      "4  5  10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {'A': [1, 2, 3, 4, 5],\n",
    "        'B': [6, 7, 8, 9, 10]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter rows where values in column 'A' are greater than 3\n",
    "filtered_df = df[df['A'] > 3]\n",
    "print(filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Value\n",
      "Category       \n",
      "A          30.0\n",
      "B          21.0\n",
      "C           2.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"     \n",
    "The groupby() function in pandas is used to split the data into groups based on some criteria. After splitting, the function applies a function to each group independently and then combines the results back into a DataFram\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {'Category': ['A', 'B', 'A', 'B', 'A', 'B','C'],\n",
    "        'Value': [10, 20, 30, 40, 50,3,2]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "grouped_df = df.groupby('Category').mean()\n",
    "print(grouped_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A   B\n",
      "0  5  10\n",
      "1  4   9\n",
      "2  3   8\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  \n",
    "\n",
    "Method chaining in pandas involves calling multiple methods on a DataFrame or Series object sequentially in a single line, which allows for more concise and readable code.\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {'A': [1, 2, 3, 4, 5],\n",
    "        'B': [6, 7, 8, 9, 10]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "\n",
    "result = df[df['A'] > 2].sort_values(by='B',ascending=False).reset_index(drop=True)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category       A     B\n",
      "Date                  \n",
      "2022-01-01  10.0  20.0\n",
      "2022-01-02  30.0  40.0\n",
      "2022-01-03  50.0   NaN\n"
     ]
    }
   ],
   "source": [
    "\"\"\"     \n",
    "The pivot_table() function in pandas is used to create a spreadsheet-style pivot table as a DataFrame.\n",
    "It allows users to summarize and aggregate data from a DataFrame according to one or more keys.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {'Date': ['2022-01-01', '2022-01-01', '2022-01-02', '2022-01-02', '2022-01-03'],\n",
    "        'Category': ['A', 'B', 'A', 'B', 'A'],\n",
    "        'Value': [10, 20, 30, 40, 50]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "pivot_table = df.pivot_table(index='Date', columns='Category', values='Value', aggfunc='sum')\n",
    "print(pivot_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n",
      "   A  B   C\n",
      "0  1  4  40\n",
      "1  2  5  60\n"
     ]
    }
   ],
   "source": [
    "\"\"\"   \n",
    "Handling duplicate rows in a DataFrame in pandas:\n",
    "\n",
    "Duplicate rows can be handled in pandas using various methods such as drop_duplicates() to remove duplicate rows, or by aggregating duplicate rows using grouping and aggregation functions.\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {'A': [1, 2, 3, 1, 2],\n",
    "        'B': [4, 5, 6, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(df_no_duplicates)\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {'A': [1, 2, 1, 2],\n",
    "        'B': [4, 5, 4, 5],\n",
    "        'C': [10, 20, 30, 40]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Aggregate duplicate rows by summing values in column 'C'\n",
    "aggregated_df = df.groupby(['A', 'B']).agg({'C': 'sum'}).reset_index()\n",
    "print(aggregated_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n",
      "3  1  4\n",
      "4  2  5\n",
      "   A  B\n",
      "0  1  4\n",
      "1  2  5\n",
      "2  3  6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {'A': [1, 2, 3, 1, 2],\n",
    "        'B': [4, 5, 6, 4, 5]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "\n",
    "\n",
    "df_no_duplicates = df.drop_duplicates()\n",
    "print(df_no_duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"   \n",
    "\n",
    "Descriptive Statistics:\n",
    "\n",
    "mean(): Computes the mean of the values.\n",
    "median(): Computes the median of the values.\n",
    "mode(): Computes the mode of the values.\n",
    "std(): Computes the standard deviation of the values.\n",
    "var(): Computes the variance of the values.\n",
    "\n",
    "\n",
    "Quantiles and Percentiles:\n",
    "\n",
    "quantile(q): Computes the qth quantile of the values.\n",
    "percentile(q): Computes the qth percentile of the values.\n",
    "Summary Statistics:\n",
    "\n",
    "describe(): Generates descriptive statistics summary of the DataFrame.\n",
    "\n",
    "\n",
    "Correlation and Covariance:\n",
    "\n",
    "corr(): Computes the pairwise correlation of columns.\n",
    "cov(): Computes the pairwise covariance of columns.\n",
    "Aggregation Functions:\n",
    "\n",
    "sum(): Computes the sum of values.\n",
    "count(): Computes the count of non-null values.\n",
    "min(): Computes the minimum value.\n",
    "max(): Computes the maximum value.\n",
    "Unique Values and Value Counts:\n",
    "\n",
    "unique(): Returns unique values in the object.\n",
    "value_counts(): Returns counts of unique values.\n",
    "Skewness and Kurtosis:\n",
    "\n",
    "skew(): Computes the skewness of the values.\n",
    "kurt(): Computes the kurtosis of the values.\n",
    "Categorical Statistics:\n",
    "\n",
    "groupby(): Group DataFrame using a mapper or by a Series of columns.\n",
    "agg(): Aggregate using one or more operations over the specified axis.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {'A': [1, 2, 3, 4, 5],\n",
    "        'B': [5, 4, 3, 2, 1]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Descriptive statistics\n",
    "print(\"Mean:\", df.mean())\n",
    "print(\"Median:\", df.median())\n",
    "print(\"Standard Deviation:\", df.std())\n",
    "print(\"Summary Statistics:\\n\", df.describe())\n",
    "\n",
    "# Correlation and Covariance\n",
    "print(\"Correlation:\\n\", df.corr())\n",
    "print(\"Covariance:\\n\", df.cov())\n",
    "\n",
    "# Aggregation functions\n",
    "print(\"Sum:\", df.sum())\n",
    "print(\"Count:\", df.count())\n",
    "print(\"Minimum:\", df.min())\n",
    "print(\"Maximum:\", df.max())\n",
    "\n",
    "# Unique values and value counts\n",
    "print(\"Unique values in column A:\", df['A'].unique())\n",
    "print(\"Value counts in column B:\\n\", df['B'].value_counts())\n",
    "\n",
    "# Skewness and Kurtosis\n",
    "print(\"Skewness:\", df.skew())\n",
    "print(\"Kurtosis:\", df.kurt())\n",
    "\n",
    "# Groupby and Aggregation\n",
    "print(\"Groupby mean:\\n\", df.groupby('B').mean())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Skewness:\n",
    "Skewness measures the asymmetry of the distribution of values around the mean of the data. A distribution is symmetric if it looks the same on both sides of the mean. Skewness quantifies the extent to which a distribution differs from this symmetry. It can be positive, negative, or zero.\n",
    "\n",
    "Positive skewness: The distribution has a longer right tail. The majority of the data points are concentrated on the left side of the mean, and the tail extends towards the right.\n",
    "Negative skewness: The distribution has a longer left tail. The majority of the data points are concentrated on the right side of the mean, and the tail extends towards the left.\n",
    "Zero skewness: The distribution is perfectly symmetric around the mean.\n",
    "\n",
    "\n",
    "\n",
    "Kurtosis:\n",
    "\n",
    "\n",
    "\n",
    "Kurtosis measures the \"tailedness\" of the distribution of values. It indicates how sharply the data points are concentrated around the mean and how heavy the tails are compared to a normal distribution.\n",
    "\n",
    "Positive kurtosis (leptokurtic): The distribution has fatter tails and a sharper peak than the normal distribution. It indicates more extreme values than would be expected under a normal distribution.\n",
    "Negative kurtosis (platykurtic): The distribution has thinner tails and a flatter peak than the normal distribution. It indicates fewer extreme values than would be expected under a normal distribution.\n",
    "Mesokurtic: The distribution has kurtosis equal to that of the normal distribution.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df_csv \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m df_excel \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m df_json \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_json(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msample.json\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_csv = pd.read_csv('sample.csv')\n",
    "\n",
    "\n",
    "df_excel = pd.read_excel('sample.xlsx')\n",
    "\n",
    "\n",
    "df_json = pd.read_json('sample.json')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "url = 'https://example.com/sample.csv'\n",
    "df_url = pd.read_csv(url)\n",
    "\n",
    "\n",
    "print(\"CSV File:\")\n",
    "print(df_csv.head())\n",
    "print(\"\\nExcel File:\")\n",
    "print(df_excel.head())\n",
    "print(\"\\nJSON File:\")\n",
    "print(df_json.head())\n",
    "\n",
    "\n",
    "print(\"\\nData from URL:\")\n",
    "print(df_url.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "loc vs iloc \n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, index=['X', 'Y', 'Z'])\n",
    "\n",
    "\n",
    "print(\"Using loc:\")\n",
    "print(\"Single row 'Y':\")\n",
    "print(df.loc['Y'])\n",
    "\n",
    "\n",
    "print(\"\\nSingle value at 'Y', 'B':\")\n",
    "print(df.loc['Y', 'B'])\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nSlice of rows and columns:\")\n",
    "print(df.loc['X':'Y', 'A':'B'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nSingle column 'C':\")\n",
    "print(df.loc[:, 'C'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"First row:\")\n",
    "print(df.iloc[0])\n",
    "\n",
    "print(\"\\nSingle value at first row, second column:\")\n",
    "print(df.iloc[0, 1])\n",
    "\n",
    "\n",
    "print(\"\\nSlice of rows and columns:\")\n",
    "print(df.iloc[0:2, 0:2])\n",
    "\n",
    "\n",
    "print(\"\\nSingle column at index 2:\")\n",
    "print(df.iloc[:, 2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "A    1\n",
      "B    4\n",
      "C    7\n",
      "Name: X, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, index=['X', 'Y', 'Z'])\n",
    "df\n",
    "# print(df.loc['Y':'Y', 'A':'C'])\n",
    "\n",
    "print(df.iloc[0, 1])\n",
    "\n",
    "print(df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "how to drop row and column in pandas :\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop the row with index label 1 from the DataFrame\n",
    "df = df.drop(1)\n",
    "\n",
    "print(df)\n",
    "\n",
    "\n",
    "# Drop the 'B' column from the DataFrame in place\n",
    "df.drop('B', axis=1, inplace=True)\n",
    "\n",
    "# Drop the row with index label 1 from the DataFrame in place\n",
    "df.drop(1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   A  B  C\n",
      "0  1  4  7\n",
      "2  3  6  9\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Drop the row with index label 1 from the DataFrame\n",
    "df = df.drop(1)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "A    4\n",
      "B    3\n",
      "C    2\n",
      "Name: count, dtype: int64\n",
      "  Category  Frequency\n",
      "0        A          4\n",
      "1        B          3\n",
      "2        C          2\n",
      "           Category  Frequency\n",
      "Index_Name                    \n",
      "0                 A          4\n",
      "1                 B          3\n",
      "2                 C          2\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "count greq of unique number :\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {\n",
    "    'Category': ['A', 'B', 'A', 'C', 'B', 'A', 'A', 'C', 'B']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "frequency_count = df['Category'].value_counts()\n",
    "\n",
    "print(frequency_count)\n",
    "\n",
    "\n",
    "\"\"\" for reset the index \"\"\"\n",
    "\n",
    "frequency_count_df = frequency_count.reset_index()\n",
    "frequency_count_df.columns = ['Category', 'Frequency']\n",
    "\n",
    "print(frequency_count_df)\n",
    "\n",
    "\n",
    "\"\"\"  rename the index on the dataframe \"\"\"\n",
    "\n",
    "frequency_count_df = frequency_count_df.rename_axis('Index_Name')\n",
    "\n",
    "print(frequency_count_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\n",
      "A    4\n",
      "B    3\n",
      "C    2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = {\n",
    "    'Category': ['A', 'B', 'A', 'C', 'B', 'A', 'A', 'C', 'B']\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "frequency_count = df['Category'].value_counts()\n",
    "\n",
    "print(frequency_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row with maximum value in column 'A':\n",
      "A    25\n",
      "B    35\n",
      "C    20\n",
      "Name: 3, dtype: int64\n",
      "\n",
      "Row with minimum value in column 'B':\n",
      "A    15\n",
      "B    20\n",
      "C    15\n",
      "Name: 2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  \n",
    "find the row for which the value of specific column is  min or max \n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "data = {\n",
    "    'A': [10, 20, 15, 25],\n",
    "    'B': [30, 25, 20, 35],\n",
    "    'C': [5, 10, 15, 20]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "max_row_A = df['A'].idxmax()\n",
    "\n",
    "\n",
    "min_row_B = df['B'].idxmin()\n",
    "\n",
    "\n",
    "print(\"Row with maximum value in column 'A':\")\n",
    "print(df.loc[max_row_A])\n",
    "\n",
    "print(\"\\nRow with minimum value in column 'B':\")\n",
    "print(df.loc[min_row_B])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "groupby():\n",
    "\n",
    "The groupby() function is used to split the DataFrame into groups based on some criteria.\n",
    "It creates a GroupBy object that contains information about how the DataFrame is split.\n",
    "You typically follow groupby() with an aggregation function to perform some operation on each group.\n",
    "\n",
    "\n",
    "aggregate() (or agg()):\n",
    "\n",
    "The aggregate() function is used to apply one or more aggregation functions to the data in each group.\n",
    "It allows you to perform custom aggregations or apply multiple aggregation functions simultaneously.\n",
    "You can use built-in aggregation functions (e.g., sum(), mean(), max()) or define custom aggregation functions.\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Category': ['A', 'B', 'A', 'C', 'B', 'A', 'A', 'C', 'B'],\n",
    "    'Value': [10, 20, 15, 25, 30, 20, 10, 35, 40]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Group the DataFrame by 'Category'\n",
    "grouped_df = df.groupby('Category')\n",
    "\n",
    "# Apply aggregation functions to each group\n",
    "agg_result = grouped_df.agg({\n",
    "    'Value': ['sum', 'mean', 'max', 'min', 'count']\n",
    "})\n",
    "\n",
    "print(agg_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "String Operation:\n",
    "Pandas provide a set of string functions for working with string data. The following are the few operations on string data:\n",
    "lower(): Any strings in the index or series are converted to lowercase letters.\n",
    "upper(): Any strings in the index or series are converted to uppercase letters.\n",
    "strip(): This method eliminates spacing from every string in the Series/index, along with a new line.\n",
    "islower(): If all of the characters in the Series/Index string are lowercase, it returns True. Otherwise, False is returned.\n",
    "isupper(): If all of the characters in the Series/Index string are uppercase, it returns True. Otherwise, False is returned.\n",
    "split(’ '): It’s a method that separates a string according to a pattern.\n",
    "cat(sep=’ '): With a defined separator, it concatenates series/index items.\n",
    "contains(pattern): If a substring is available in the current element, it returns True; otherwise, it returns False.\n",
    "replace(a,b): It substitutes the value b for the value a.\n",
    "startswith(pattern): If all of the components in the series begin with a pattern, it returns True.\n",
    "endswith(pattern): If all of the components in the series terminate in a pattern, it returns True.\n",
    "find(pattern): It can be used to return the pattern’s first occurrence.\n",
    "findall(pattern): It gives you a list of all the times the pattern appears.\n",
    "swapcase: It is used to switch the lower/upper case.\n",
    "\n",
    "Null values:\n",
    " When no data is being sent to the items, a Null value/missing value can appear. There may be no values in the respective columns, which are commonly represented as NaN. Pandas provide several useful functions for identifying, deleting, and changing null values in Data Frames. The following are the functions.\n",
    "isnull(): isnull 's job is to return true if either of the rows has null values.\n",
    "notnull(): It is the inverse of the isnull() function, returning true values for non-null values.\n",
    "dropna(): This function evaluates and removes null values from rows and columns.\n",
    "fillna(): It enables users to substitute other values for the NaN values.\n",
    "replace(): It’s a powerful function that can take the role of a regex, dictionary, string, series, and more.\n",
    "interpolate(): It’s a useful function for filling null values in a series or data frame.\n",
    "\n",
    "\n",
    "Row and column selection: We can retrieve any row and column of the DataFrame by specifying the names of the rows and columns. It is one-dimensional and is regarded as a Series when you select it from the DataFrame.\n",
    "\n",
    "\n",
    "Filter Data: By using some of the boolean logic in DataFrame, we can filter the data.\n",
    "\n",
    "\n",
    "Count Values: Using the ‘value counts()’ option, this process is used to count the overall possible combinations.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A     6\n",
      "B    15\n",
      "dtype: int64\n",
      "   A   B\n",
      "0  1  16\n",
      "1  4  25\n",
      "2  9  36\n",
      "0    feline\n",
      "1    canine\n",
      "2     avian\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "apply():\n",
    "\n",
    "The apply() method is used to apply a function along an axis of the DataFrame or Series.\n",
    "\n",
    "It can be used with both DataFrame and Series objects.\n",
    "When applied to a DataFrame, apply() allows you to apply a function along the rows or columns (specified by the axis parameter).\n",
    "\n",
    "When applied to a Series, apply() allows you to apply a function element-wise to each element in the Series.\n",
    "\n",
    "\n",
    "applymap():\n",
    "\n",
    "The applymap() method is a DataFrame method and is used to apply a function to every element of the DataFrame.\n",
    "\n",
    "It applies the function to each element independently, irrespective of rows or columns.\n",
    "\n",
    "applymap() is particularly useful when you want to apply an element-wise operation to every cell in a DataFrame.\n",
    "\n",
    "\n",
    "map():\n",
    "\n",
    "The map() method is a Series method and is used to substitute each value in a Series with another value.\n",
    "It's primarily used for mapping values from one domain to another or for substituting specific values with other values.\n",
    "map() is not applicable to DataFrames directly, only to Series.\n",
    "Here's a brief comparison:\n",
    "\n",
    "apply() is used for applying a function along the rows or columns of a DataFrame or element-wise to a Series.\n",
    "applymap() is used specifically for applying a function to every element of a DataFrame.\n",
    "\n",
    "map() is used for substituting each value in a Series with another value. \n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})\n",
    "\n",
    "# Using apply() on DataFrame to calculate the sum of each column\n",
    "print(df.apply(sum, axis=0))\n",
    "\n",
    "# Using applymap() to square every element in the DataFrame\n",
    "print(df.applymap(lambda x: x ** 2))\n",
    "\n",
    "# Sample Series\n",
    "s = pd.Series(['cat', 'dog', 'bird'])\n",
    "\n",
    "# Using map() to substitute values in the Series\n",
    "print(s.map({'cat': 'feline', 'dog': 'canine', 'bird': 'avian'}))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "merge():\n",
    "The merge() function in Pandas is used to merge two DataFrames based on the values of the specified columns.\n",
    "It is similar to SQL join operations.\n",
    "It can perform inner, outer, left, and right joins.\n",
    "\n",
    "\n",
    "join():\n",
    "The join() method in Pandas is used to combine columns of two potentially differently-indexed DataFrames into a single result DataFrame.\n",
    "It uses indexes to join DataFrames.\n",
    "\n",
    "\n",
    "concatenate():\n",
    "The concatenate() function in Pandas is used to concatenate two or more DataFrames along rows or columns.\n",
    "It does not perform any joins or merges based on values or indexes.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Creating DataFrame df1\n",
    "df1 = pd.DataFrame({\n",
    "    'A': ['A0', 'A1', 'A2'],\n",
    "    'B': ['B0', 'B1', 'B2']\n",
    "})\n",
    "\n",
    "# Creating DataFrame df2\n",
    "df2 = pd.DataFrame({\n",
    "    'A': ['A3', 'A4', 'A5'],\n",
    "    'B': ['B3', 'B4', 'B5']\n",
    "})\n",
    "\n",
    "\n",
    "# Using merge() to perform an inner join on the 'A' column\n",
    "merge_result = pd.merge(df1, df2, on='A', how='inner')\n",
    "print(\"Merge Result (Inner Join):\")\n",
    "print(merge_result)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Creating DataFrame df1 with a new index\n",
    "df1 = pd.DataFrame({\n",
    "    'A': ['A0', 'A1', 'A2'],\n",
    "    'B': ['B0', 'B1', 'B2']\n",
    "}, index=['X', 'Y', 'Z'])\n",
    "\n",
    "# Creating DataFrame df2 with the same index as df1\n",
    "df2 = pd.DataFrame({\n",
    "    'C': ['C0', 'C1', 'C2'],\n",
    "    'D': ['D0', 'D1', 'D2']\n",
    "}, index=['X', 'Y', 'Z'])\n",
    "\n",
    "# Using join() to perform a left join based on the index\n",
    "join_result = df1.join(df2)\n",
    "print(\"\\nJoin Result (Left Join):\")\n",
    "print(join_result)\n",
    "\n",
    "\n",
    "# Using concatenate() to concatenate the DataFrames along rows\n",
    "concat_result = pd.concat([df1, df2])\n",
    "print(\"\\nConcatenate Result (Along Rows):\")\n",
    "print(concat_result)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "How Do you optimize the performance while working with large datasets in pandas?\n",
    "\n",
    "Load less data: While reading data using pd.read_csv(), choose only the columns you need with the “usecols” parameter to avoid loading unnecessary data. Plus, specifying the “chunksize” parameter splits the data into different chunks and processes them sequentially.\n",
    "\n",
    "Avoid loops: Loops and iterations are expensive, especially when working with large datasets. Instead, opt for vectorized operations, as they are applied on an entire column at once, making them faster than row-wise iterations.\n",
    "\n",
    "Use data aggregation: Try aggregating data and perform statistical operations because operations on aggregated data are more efficient than on the entire dataset.\n",
    "\n",
    "Use the right data types: \n",
    "The default data types in pandas are not memory efficient. For example, integer values take the default datatype of int64, but if your values can fit in int32, adjusting the datatype to int32 can optimize the memory usage.\n",
    "\n",
    "Parallel processing:\n",
    " Dask is a pandas-like API to work with large datasets. It utilizes multiple processes of your system to parallely execute different data tasks. \n",
    "\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Name  Age  Score\n",
      "1      Bob   20     90\n",
      "0    Alice   25     80\n",
      "2  Charlie   30     75\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "sort values based on columns :\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 20, 30],\n",
    "    'Score': [80, 90, 75]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Sort the DataFrame by the 'Age' column in ascending order\n",
    "sorted_df = df.sort_values(by='Age')\n",
    "\n",
    "print(sorted_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "different ways to filter the values :\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma'],\n",
    "    'Age': [25, 30, 35, 40, None],\n",
    "    'Category': ['A', 'B', 'A', 'C', 'B'],\n",
    "    'Score': [80, 90, 75, 85, 95]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Filter data using boolean indexing\n",
    "bool_filtered_df = df[df['Age'] > 30]\n",
    "\n",
    "# Filter data using query method\n",
    "query_filtered_df = df.query('Age > 30')\n",
    "\n",
    "# Filter data using loc method\n",
    "loc_filtered_df = df.loc[df['Age'] > 30]\n",
    "\n",
    "# Filter data using isin method\n",
    "isin_filtered_df = df[df['Category'].isin(['A', 'B'])]\n",
    "\n",
    "# Filter data using isna method\n",
    "na_filtered_df = df[df['Age'].isna()]\n",
    "\n",
    "# Filter data using string methods\n",
    "string_filtered_df = df[df['Name'].str.contains('a', case=False)]\n",
    "\n",
    "# Groupby and filter\n",
    "grouped_filtered_df = df.groupby('Category').filter(lambda x: x['Score'].mean() > 80)\n",
    "\n",
    "print(\"Boolean Indexing:\")\n",
    "print(bool_filtered_df)\n",
    "\n",
    "print(\"\\nQuery Method:\")\n",
    "print(query_filtered_df)\n",
    "\n",
    "print(\"\\nLoc Method:\")\n",
    "print(loc_filtered_df)\n",
    "\n",
    "print(\"\\nIsin Method:\")\n",
    "print(isin_filtered_df)\n",
    "\n",
    "print(\"\\nIsna Method:\")\n",
    "print(na_filtered_df)\n",
    "\n",
    "print(\"\\nString Methods:\")\n",
    "print(string_filtered_df)\n",
    "\n",
    "print(\"\\nGroupby and Filter:\")\n",
    "print(grouped_filtered_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"   \n",
    "How do you handle null or missing values in pandas?\n",
    "\n",
    "\n",
    "You can use any of the following three methods to handle missing values in pandas:\n",
    "\n",
    "dropna() – the function removes the missing rows or columns from the DataFrame.\n",
    "\n",
    "fillna() – fill nulls with a specific value using this function.\n",
    "\n",
    "interpolate() – this method fills the missing values with computed interpolation values. The interpolation technique can be linear, polynomial, spline, time, etc.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "\n",
    "Difference between fillna() and interpolate() methods\n",
    "fillna() –\n",
    "\n",
    "fillna() fills the missing values with the given constant. Plus, you can give forward-filling or backward-filling inputs to its ‘method’ parameter.\n",
    "\n",
    "interpolate() –\n",
    "\n",
    "\n",
    "By default, this function fills the missing or NaN values with the linear interpolated values. However, you can customize the interpolation technique to polynomial, time, index, spline, etc., using its ‘method’ parameter.\n",
    "\n",
    "The interpolation method is highly suitable for time series data, whereas fillna is a more generic approach.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"  \n",
    "What is Resampling?\n",
    "Resampling is used to change the frequency at which time series data is reported. Imagine you have monthly time series data and want to convert it into weekly data or yearly, this is where resampling is used.\n",
    "\n",
    "Converting monthly to weekly or daily data is nothing but upsampling. Interpolation techniques are used to increase the frequencies here.\n",
    "converting monthly to yearly data is termed as downsampling, where data aggregation techniques are applied.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cateline</th>\n",
       "      <th>John</th>\n",
       "      <th>Matt</th>\n",
       "      <th>Oliver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cateline   John   Matt  Oliver\n",
       "0     False   True  False   False\n",
       "1      True  False  False   False\n",
       "2     False  False   True   False\n",
       "3     False  False  False    True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"   \n",
    "How do you perform one-hot encoding using pandas?\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Name': ['John', 'Cateline', 'Matt', 'Oliver'],\n",
    "        'ID': [1, 22, 23, 36]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "new_df = pd.get_dummies(df.Name)\n",
    "new_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Name   id Gender  Age\n",
      "0   ram  101      M   21\n",
      "1  ravi  102      M   25\n",
      "2  sham  103      M   24\n",
      "3  sita  104      F   28\n",
      "4  gita  105      F   25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ram</td>\n",
       "      <td>101</td>\n",
       "      <td>Male</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ravi</td>\n",
       "      <td>102</td>\n",
       "      <td>Male</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sham</td>\n",
       "      <td>103</td>\n",
       "      <td>Male</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sita</td>\n",
       "      <td>104</td>\n",
       "      <td>F</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gita</td>\n",
       "      <td>105</td>\n",
       "      <td>F</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name   id Gender  Age\n",
       "0   ram  101   Male   30\n",
       "1  ravi  102   Male   25\n",
       "2  sham  103   Male   24\n",
       "3  sita  104      F   28\n",
       "4  gita  105      F   25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "EmpData=pd.DataFrame({'Name': ['ram','ravi','sham','sita','gita'],\n",
    "                            'id': [101,102,103,104,105],\n",
    "                        'Gender': ['M','M','M','F','F'],\n",
    "                           'Age': [21,25,24,28,25]\n",
    "                          })\n",
    "\n",
    "print(EmpData)\n",
    " \n",
    " \n",
    "# Replacing values in data globally for all the columns\n",
    "# Wherever you find values, replace them: M-->Male, and 21-->22\n",
    "EmpDataReplaced=EmpData.replace(to_replace={'M':'Male', 21:30}, inplace=False)\n",
    "EmpDataReplaced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame after replacing values in 'Category' column:\n",
      "      Name   Age    Category  Score\n",
      "0    Alice  25.0  Category_A     80\n",
      "1      Bob  30.0  Category_B     90\n",
      "2  Charlie  35.0  Category_A     75\n",
      "3    David  40.0           C     85\n",
      "4     Emma   NaN  Category_B     95\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Emma'],\n",
    "    'Age': [25, 30, 35, 40, None],\n",
    "    'Category': ['A', 'B', 'A', 'C', 'B'],\n",
    "    'Score': [80, 90, 75, 85, 95]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "df['Category'] = df['Category'].replace({'A': 'Category_A', 'B': 'Category_B'})\n",
    "\n",
    "print(\"DataFrame after replacing values in 'Category' column:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after replacing a range of values in 'Age' column:\n",
      "      Name   Age    Category  Score\n",
      "0    Alice  25.0  Category_A     80\n",
      "1      Bob  35.0  Category_B     90\n",
      "2  Charlie  35.0  Category_A     75\n",
      "3    David  40.0           C     85\n",
      "4     Emma   NaN  Category_B     95\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df.loc[(df['Age'] >= 30) & (df['Age'] < 40), 'Age'] = 35\n",
    "\n",
    "print(\"\\nDataFrame after replacing a range of values in 'Age' column:\")\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy questions \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy Array:\n",
      "[1 2 3 4 5]\n",
      "Type of array: <class 'numpy.ndarray'>\n",
      "Data type of elements: int64\n",
      "Shape of array: (5,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"    \n",
    "Main datastructures in Nuture of Numpy ?\n",
    "\n",
    "\n",
    "The main data structure in NumPy is the ndarray, short for n-dimensional array. It is a powerful data structure that allows for efficient storage and manipulation of arrays containing homogeneous data (data of the same type).\n",
    "\n",
    "\n",
    "Here are some key characteristics of ndarrays:\n",
    "\n",
    "Homogeneous Data: All elements in a NumPy ndarray must be of the same data type, unlike Python lists which can contain elements of different data types.\n",
    "\n",
    "Fixed Size: The size of a NumPy array is fixed upon creation, meaning you cannot resize it like a Python list.\n",
    "\n",
    "Efficient Computation: NumPy arrays are implemented in C, which allows for efficient computation and vectorized operations.\n",
    "\n",
    "Multi-dimensional: NumPy arrays can have any number of dimensions. A one-dimensional array is like a list, a two-dimensional array is like a matrix, and so on.\n",
    "\n",
    "Indexing and Slicing: Similar to Python lists, you can access elements of a NumPy array using indexing and slicing.\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "arr = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "print(\"NumPy Array:\")\n",
    "print(arr)\n",
    "print(\"Type of array:\", type(arr))\n",
    "print(\"Data type of elements:\", arr.dtype)\n",
    "print(\"Shape of array:\", arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "NumPy is a fundamental library in data science and machine learning.\n",
    "\n",
    "Efficient Array Operations: NumPy provides high-performance multidimensional array objects (ndarray) and tools for working with these arrays. This allows for efficient storage and manipulation of large datasets, making it essential for handling data in data science tasks.\n",
    "\n",
    "Vectorized Operations: NumPy supports vectorized operations, allowing mathematical and logical operations to be performed on entire arrays without the need for explicit looping. This makes code concise, readable, and computationally efficient.\n",
    "\n",
    "Broadcasting: NumPy's broadcasting capability allows arrays of different shapes to be combined in arithmetic operations. This simplifies code and makes it easier to work with arrays of different dimensions, which is common in data science tasks.\n",
    "\n",
    "Random Number Generation: NumPy provides functions for generating random numbers and sampling from various probability distributions. This is useful for simulating data, bootstrapping, and conducting statistical experiments in data science.\n",
    "\n",
    "Integration with Other Libraries: NumPy is a foundational library in the Python ecosystem and is extensively used by other libraries and frameworks in data science, such as Pandas, SciPy, Matplotlib, and scikit-learn. These libraries often accept NumPy arrays as input or return NumPy arrays as output.\n",
    "\n",
    "Interfacing with Low-Level Languages:\n",
    " \n",
    "NumPy is implemented in C and Fortran, which makes it efficient for numerical computations. It also provides interfaces to libraries written in these languages, enabling seamless integration with existing computational libraries and frameworks.\n",
    "\n",
    "Linear Algebra Operations: \n",
    "\n",
    "NumPy provides a rich set of functions for linear algebra operations, including matrix multiplication, eigenvalue decomposition, singular value decomposition, and solving linear systems of equations. These operations are fundamental in many data science applications, such as machine learning and optimization.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "There are several reasons why NumPy is an important library in Python: \n",
    "\n",
    "Efficient operations on arrays and matrices:\n",
    " NumPy is designed to be efficient for numerical computing. It provides functions and methods for performing operations on large arrays and matrices of data that are much faster than using Python's built-in data structures. NumPy provides efficient, vectorized operations on arrays and matrices, which can be much faster than looping over the elements of the array and performing the operation manually.\n",
    "\n",
    "Large collection of mathematical functions:\n",
    " NumPy provides a large collection of mathematical functions that can be applied to arrays and matrices, such as trigonometric functions, exponential functions, and linear algebra functions. This can save a lot of time and effort compared to implementing these functions yourself. \n",
    "\n",
    "\n",
    "Interoperability with other libraries:\n",
    "NumPy is designed to work seamlessly with these libraries, making it easy to use them together. NumPy is integrated with many other popular Python libraries, such as Pandas (a library for data analysis) and Matplotlib (a library for data visualization). This allows you to use NumPy arrays in these libraries and take advantage of their functionality. \n",
    "\n",
    "Widely used in scientific computing:\n",
    " NumPy is widely used in the scientific computing and data science communities, and is often used in conjunction with other libraries such as Pandas and SciPy. Since NumPy is an essential library for scientific computing in Python, it is widely used in machine learning, data science, and other fields that require efficient operations on large arrays of numerical data.  \n",
    "\n",
    "\n",
    "Support for large datasets: \n",
    "NumPy is designed to handle large datasets efficiently, allowing you to work with datasets that may not fit in memory using other data structures.\n",
    "\n",
    "Easy to use:\n",
    " NumPy provides a simple and intuitive interface for working with numerical data in Python. Its syntax is similar to Python's built-in data types and it integrates well with other libraries, such as Matplotlib for visualization. \n",
    "\n",
    "Support for high-level mathematical functions: \n",
    "NumPy provides support for a wide range of mathematical functions, such as trigonometric functions, logarithms, and exponential functions. These functions are implemented in a highly efficient manner, making it easy to perform complex mathematical operations with NumPy. \n",
    "\n",
    "\n",
    "Support for array broadcasting: \n",
    "NumPy's support for array broadcasting allows you to perform arithmetic operations on arrays of different sizes, making it easy to work with arrays of different shapes and dimensions.\n",
    "\n",
    "Flexibility:\n",
    "NumPy arrays can be used to store data of any type and can be easily resized or reshaped to fit the needs of your application. \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"   \n",
    "why numpy preferd over  Matlab, Octave ? \n",
    "\n",
    "\n",
    "Powerful functions for performing complex mathematical operations on multi-dimensional matrices and arrays. The operations on ndarrays of NumPy are approximately up to 50% faster when compared to operations on native lists using loops. This efficiency is very much useful when the arrays have millions of elements.\n",
    "Provides indexing syntax to access portions of data easily in a large array.\n",
    "Provides built-in functions which help to easily perform operations related to linear algebra and statistics.\n",
    "It takes only a few lines of code to achieve complex computations using NumPy.\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "How are NumPy arrays better than Python’s lists?\n",
    "\n",
    "\n",
    "Python lists support storing heterogeneous data types whereas NumPy arrays can store datatypes of one nature itself. \n",
    "\n",
    "NumPy provides extra functional capabilities that make operating on its arrays easier which makes NumPy array advantageous in comparison to Python lists as those functions cannot be operated on heterogeneous data.\n",
    "\n",
    "NumPy arrays are treated as objects which results in minimal memory usage. Since Python keeps track of objects by creating or deleting them based on the requirements, NumPy objects are also treated the same way. This results in lesser memory wastage.\n",
    "\n",
    "NumPy arrays support multi-dimensional arrays.\n",
    "\n",
    "NumPy provides various powerful and efficient functions for complex computations on the arrays.\n",
    "\n",
    "NumPy also provides various range of functions for BitWise Operati\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "what are the different types of data types in numpy? \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "arr_int32 = np.array([1, 2, 3], dtype=np.int32)\n",
    "arr_float64 = np.array([1.0, 2.0, 3.0], dtype=np.float64)\n",
    "arr_complex128 = np.array([1 + 2j, 3 + 4j], dtype=np.complex128)\n",
    "arr_bool = np.array([True, False, True], dtype=np.bool)\n",
    "arr_string = np.array(['apple', 'banana', 'cherry'], dtype=np.str)\n",
    "\n",
    "# Printing arrays and their data types\n",
    "print(\"Integer Array (int32):\", arr_int32)\n",
    "print(\"Float Array (float64):\", arr_float64)\n",
    "print(\"Complex Array (complex128):\", arr_complex128)\n",
    "print(\"Boolean Array (bool):\", arr_bool)\n",
    "print(\"String Array (str):\", arr_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "Here are a few examples of situations where NumPy might be useful: \n",
    "\n",
    "Scientific computing:\n",
    " NumPy provides a number of functions and features that are useful for scientific computing tasks, such as numerical integration, linear algebra, and random number generation. \n",
    "\n",
    "Data analysis:\n",
    " NumPy is often used as a foundation for other libraries that are used for data analysis, such as Pandas and SciPy. It provides functions for reading and writing data to and from files, as well as functions for performing statistical analysis and manipulating data. \n",
    "\n",
    " \n",
    "Machine learning:\n",
    " NumPy is frequently used in machine learning tasks, such as preparing data, creating training and testing sets, and implementing algorithms. It provides a number of functions that are useful for these tasks, such as matrix multiplication and element-wise operations. \n",
    "\n",
    "Image processing:\n",
    " NumPy is often used for image processing tasks, such as resizing and cropping images, as well as applying filters and transformations. It provides functions for working with arrays of pixel values, which can be used to represent images. \n",
    "\n",
    "\n",
    "Data visualization:\n",
    " NumPy can be used to create data visualizations such as histograms, scatter plots, and line plots. It provides functions for generating data to be plotted as well as functions for creating plots using Matplotlib or other visualization libraries. \n",
    "\n",
    "Data manipulation:\n",
    " NumPy provides functions for efficiently manipulating large arrays of data, such as selecting specific elements or subarrays, sorting, and reshaping. \n",
    "\n",
    "Optimization:\n",
    " NumPy provides functions for minimizing or maximizing objective functions, such as NumPy.argmin and NumPy.argmax, which can be used to find the optimal parameters for a given model. \n",
    "\n",
    " \n",
    "Signal processing:\n",
    " NumPy provides functions for performing tasks such as filtering, convolution, and correlation, which are commonly used in signal processing. \n",
    "\n",
    "Text processing: \n",
    "NumPy can be used to encode and decode text data for use in natural language processing tasks. \n",
    "\n",
    "Financial modeling:\n",
    " NumPy can be used to perform financial modeling tasks, such as calculating returns, risk, and portfolio optimization.\n",
    "\n",
    "Simulation:\n",
    " NumPy can be used to generate random numbers and perform simulations, such as Monte Carlo simulations.\n",
    "\n",
    "Computer vision:\n",
    " NumPy can be used to process and manipulate images and video data for use in computer vision tasks.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simple Mean (np.mean()): 3.0\n",
      "Weighted Average (np.average()): 3.2\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "Difference between the mean() and average in numpy :\n",
    "\n",
    "\n",
    "np.mean():\n",
    "\n",
    "Calculates the arithmetic mean of the elements in the array.\n",
    "By default, it computes the simple average, treating all elements equally.\n",
    "Offers additional options like specifying axis along which the mean is computed, data types, and where the result should be placed.\n",
    "Does not inherently support weighted averages.\n",
    "\n",
    "\n",
    "\n",
    "np.average():\n",
    "\n",
    "Computes the weighted average of the elements in the array if the weights parameter is specified.\n",
    "Allows for the elements to contribute unequally to the final average based on their weights.\n",
    "Useful when you want to give different importance to different elements in the array.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Example data\n",
    "data = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Calculating mean using np.mean()\n",
    "mean_simple = np.mean(data)\n",
    "print(\"Simple Mean (np.mean()):\", mean_simple)\n",
    "\n",
    "#\n",
    "weights = np.array([0.1, 0.2, 0.3, 0.2, 0.2]) \n",
    "weighted_average = np.average(data, weights=weights)\n",
    "print(\"Weighted Average (np.average()):\", weighted_average)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency of 2 in the array: 3\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  \n",
    "How do you count the frequency of a given positive value appearing in the NumPy array?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "arr = np.array([1, 2, 3, 4, 5, 2, 3, 4, 2, 1])\n",
    "\n",
    "\n",
    "value_to_count = 2\n",
    "\n",
    "\n",
    "frequency = np.count_nonzero(arr == value_to_count)\n",
    "\n",
    "print(\"Frequency of\", value_to_count, \"in the array:\", frequency)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr[:, 0]:\n",
      " [1 4 7]\n",
      "Shape of result: (3,)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"  \n",
    "How is arr[:,0] different from arr[:,[0]] give two example similar to this ?\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array([[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]])\n",
    "\n",
    "result = arr[:, 0]\n",
    "\n",
    "print(\"arr[:, 0]:\\n\", result)\n",
    "print(\"Shape of result:\", result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arr[:, [0]]:\n",
      " [[1]\n",
      " [4]\n",
      " [7]]\n",
      "Shape of result: (3, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.array([[1, 2, 3],\n",
    "                [4, 5, 6],\n",
    "                [7, 8, 9]])\n",
    "\n",
    "result = arr[:, [0]]\n",
    "\n",
    "print(\"arr[:, [0]]:\\n\", result)\n",
    "print(\"Shape of result:\", result.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result of element-wise addition: [ 6  8 10 12]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"   \n",
    "Vectorization in NumPy refers to the ability to apply operations element-wise on entire arrays, which is more efficient than using traditional Python loops. It leverages optimized C and Fortran code under the hood to execute these operations efficiently.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "a = np.array([1, 2, 3, 4])\n",
    "b = np.array([5, 6, 7, 8])\n",
    "\n",
    "result = a + b\n",
    "\n",
    "print(\"Result of element-wise addition:\", result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"   \n",
    "convert  data frame  into  array ? \n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "\n",
    "numpy_array = df.values\n",
    "\n",
    "print(\"NumPy Array:\")\n",
    "print(numpy_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "How is Vectorization related to Broadcasting in NumPy?\n",
    "\n",
    "Vectorization involves delegating NumPy operations internally to optimized C language functions to result in faster Python code. Whereas Broadcasting refers to the methods that allow NumPy to perform array-related arithmetic operations. The size or shape of the arrays does not matter in this case. Broadcasting solves the problem of mismatched shaped arrays by replicating the smaller array along the larger array to ensure both arrays are having compatible shapes for NumPy operations. Performing Broadcasting before Vectorization helps to vectorize operations which support arrays of different dimensions.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"    \n",
    "Write a program to repeat each of the elements five times for a given array.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "given_array = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "\n",
    "repeated_array = np.repeat(given_array, 5)\n",
    "\n",
    "print(\"Original Array:\", given_array)\n",
    "print(\"Array with each element repeated five times:\", repeated_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing Array:\n",
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "\n",
      "New Array with Zeros Border:\n",
      "[[0 0 0 0 0]\n",
      " [0 1 2 3 0]\n",
      " [0 4 5 6 0]\n",
      " [0 7 8 9 0]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" how to add zero at border in numpy   \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "existing_array = np.array([[1, 2, 3],\n",
    "                           [4, 5, 6],\n",
    "                           [7, 8, 9]])\n",
    "\n",
    "\n",
    "rows, cols = existing_array.shape\n",
    "\n",
    "# Create a new array with zeros and expanded dimensions\n",
    "new_array = np.zeros((rows + 2, cols + 2), dtype=existing_array.dtype)\n",
    "\n",
    "# Assign the existing array to the center of the new array\n",
    "new_array[1:-1, 1:-1] = existing_array\n",
    "\n",
    "print(\"Existing Array:\")\n",
    "print(existing_array)\n",
    "\n",
    "print(\"\\nNew Array with Zeros Border:\")\n",
    "print(new_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array: [1 2 3 4 5 6 7 8 9]\n",
      "Sub-Arrays: [array([1, 2, 3]), array([4, 5, 6]), array([7, 8, 9])]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "how to split array into different parts in numpy ?\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample array\n",
    "arr = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "\n",
    "# Split the array into 3 sub-arrays\n",
    "sub_arrays = np.array_split(arr, 3)\n",
    "\n",
    "print(\"Original Array:\", arr)\n",
    "print(\"Sub-Arrays:\", sub_arrays)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized Array:\n",
      "[[1 2 3 4]\n",
      " [5 6 1 2]\n",
      " [3 4 5 6]]\n",
      "\n",
      "Reshaped Array:\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"   \n",
    "How to rehshape and resize array in numpy ?\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "arr = np.array([[1, 2, 3],\n",
    "                [4, 5, 6]])\n",
    "\n",
    "\n",
    "resized_arr = np.resize(arr, (3, 4))\n",
    "\n",
    "print(\"Resized Array:\")\n",
    "print(resized_arr)\n",
    "\n",
    "reshaped_arr = np.reshape(arr, (3, 2))\n",
    "\n",
    "print(\"\\nReshaped Array:\")\n",
    "print(reshaped_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Array: [3 1 2 5 4]\n",
      "Sorted Array: [1 2 3 4 5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a sample array\n",
    "arr = np.array([3, 1, 2, 5, 4])\n",
    "\n",
    "# Sort the array\n",
    "sorted_arr = np.sort(arr)\n",
    "\n",
    "print(\"Original Array:\", arr)\n",
    "print(\"Sorted Array:\", sorted_arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "data_dict = {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n",
    "\n",
    "\n",
    "values = list(data_dict.values())\n",
    "\n",
    "\n",
    "numpy_array = np.array(values)\n",
    "\n",
    "print(\"NumPy Array from Dictionary Values:\", numpy_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array:\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "Type of array: <class 'numpy.ndarray'>\n",
      "\n",
      "Matrix:\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "Type of matrix: <class 'numpy.matrix'>\n"
     ]
    }
   ],
   "source": [
    "\"\"\"   \n",
    "Arrays (numpy.ndarray):\n",
    "\n",
    "Arrays can have any number of dimensions (1D, 2D, 3D, etc.).\n",
    "Arrays are the fundamental data structure in NumPy.\n",
    "Arrays support element-wise operations.\n",
    "Arrays are more flexible and commonly used in numerical computing and data analysis.\n",
    "You can create arrays using np.array() function.\n",
    "\n",
    "\n",
    "Matrices (numpy.matrix):\n",
    "\n",
    "Matrices are a subclass of arrays and always have exactly two dimensions (rows and columns).\n",
    "Matrices support matrix multiplication with the * operator.\n",
    "\n",
    "Matrices have some additional methods like I for computing the inverse and T for computing the transpose.\n",
    "\n",
    "Matrices can be less flexible compared to arrays, especially when dealing with operations beyond linear algebra.\n",
    "\n",
    "You can create matrices using np.matrix() function.\n",
    "\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "array_a = np.array([[1, 2], [3, 4]])\n",
    "\n",
    "matrix_b = np.matrix([[1, 2], [3, 4]])\n",
    "\n",
    "print(\"Array:\")\n",
    "print(array_a)\n",
    "print(\"Type of array:\", type(array_a))\n",
    "\n",
    "print(\"\\nMatrix:\")\n",
    "print(matrix_b)\n",
    "print(\"Type of matrix:\", type(matrix_b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
